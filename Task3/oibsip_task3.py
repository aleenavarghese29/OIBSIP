# -*- coding: utf-8 -*-
"""OIBSIP_Task3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vvtk9E7geY4M0fkOu44QKRerEjO4lVO5

# **Car Price Prediction with Machine Learning**

## **Import Required Libraries**
"""

# Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""## **Load the dataset**"""

df=pd.read_csv('/content/car data.csv')
df.head()

"""## **Exploratory Data Analysis (EDA)**"""

#Check for Missing Values

print(df.isnull().sum())

#Summary Statistics
print(df.describe())

sns.set_style("whitegrid")  # Use a clean Seaborn style

# Define a color palette for variety
colors = ['#FF6F61', '#6B4226', '#1E90FF', '#228B22', '#FFD700', '#8A2BE2']

# Loop through numerical columns and plot histograms
for i, column in enumerate(df.select_dtypes(include=['number']).columns):
    fig, ax = plt.subplots(figsize=(9, 6))  # Increase figure size

    # Use different colors from the list
    sns.histplot(df[column], bins=30, color=colors[i % len(colors)], edgecolor='black', kde=True, ax=ax)

    # Improve title and labels
    ax.set_title(f"Distribution of {column}", fontsize=14, fontweight='bold')
    ax.set_xlabel(column, fontsize=12)
    ax.set_ylabel("Frequency", fontsize=12)

    plt.show()

#Correlation Heatmap
numerical_df = df.select_dtypes(include=['number']) # Select only numerical columns
plt.figure(figsize=(10, 6))
sns.heatmap(numerical_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Feature Correlation Heatmap")
plt.show()

#Relationship Between Features and Target Variable

# Selling Price vs. Present Price
plt.figure(figsize=(8, 6))
sns.scatterplot(x=df["Present_Price"], y=df["Selling_Price"])
plt.title("Present Price vs. Selling Price")
plt.show()

# Selling Price vs. Driven KMs
plt.figure(figsize=(8, 6))
sns.scatterplot(x=df["Driven_kms"], y=df["Selling_Price"])
plt.title("Driven KMs vs. Selling Price")
plt.show()

"""## **Data Preprocessing**"""

# Calculate Car Age
df["Car_Age"] = 2025 - df["Year"]

# Drop 'Year' and 'Car_Name' (not useful for prediction)
df.drop(columns=["Year", "Car_Name"], inplace=True)

#Convert Categorical Features into Numerical
df = pd.get_dummies(df, columns=["Fuel_Type", "Selling_type", "Transmission"], drop_first=True)

print(df.head())

#Train-Test Split
X = df.drop(columns=["Selling_Price"])  # Features
y = df["Selling_Price"]  # Target Variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### **Train Machine Learning Model**"""

# Train Random Forest Model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

"""### **Model Evaluation**"""

# Predictions
y_pred = model.predict(X_test)

# Evaluation Metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# Print Metrics
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

"""## **Feature Importance**"""

# Get feature importance values
importances = model.feature_importances_
feature_names = X.columns

# Create a DataFrame for better sorting and visualization
feature_importance_df = pd.DataFrame({"Feature": feature_names, "Importance": importances})
feature_importance_df = feature_importance_df.sort_values(by="Importance", ascending=False)  # Sort by importance

# Plot
plt.figure(figsize=(12, 6))  # Increase figure size
sns.barplot(x=feature_importance_df["Importance"], y=feature_importance_df["Feature"])
plt.xlabel("Feature Importance Score", fontsize=14)
plt.ylabel("Features", fontsize=14)
plt.title("Feature Importance of Car Price Prediction Model", fontsize=16)
plt.tight_layout()  # Adjust spacing
plt.show()

"""## **Saving the Trained Model for Future Use**"""

import joblib

# Save the trained model to a file
joblib.dump(model, 'car_price_prediction_model.pkl')

# To load the model back later
loaded_model = joblib.load('car_price_prediction_model.pkl')

# Predict using the loaded model
predicted_price = loaded_model.predict(new_car_df)
print(f"The predicted price for the new car is: {predicted_price[0]:.2f} Lakhs")